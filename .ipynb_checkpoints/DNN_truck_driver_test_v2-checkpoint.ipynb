{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from darkflow.net.build import TFNet\n",
    "import random as rd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion_rate = 2\n",
    "path_test_data = \"../training/\"\n",
    "#path_test_data = \"labels/cup/images/\"\n",
    "path_result_folder = \"mlp-training/result/\"\n",
    "path_premlp = \"mlp-training/result/premlp/\"\n",
    "path_original = \"mlp-training/result/original/\"\n",
    "path_cup = \"labels/cup/images/\"\n",
    "path_cellphone = \"labels/cellphone/images/\"\n",
    "path_paper = \"labels/paper/images/\"\n",
    "path_mlp_training = \"mlp-training/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"model\": \"cfg/truck-yolo.cfg\", \"load\": -1, \"gpu\":0.75,\"threshold\":0.9}\n",
    "#options = {\"model\": \"cfg/truck-yolo.cfg\", \"load\": 56500, \"gpu\":0.75}\n",
    "path_yolo_test = \"labels/cellphone/images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mlp_sample_image = \"mlp-training/cellphone-0.jpg\"\n",
    "path_mlp_csv = \"mlp-training/csv/truck_driver.csv\"\n",
    "path_mlp_model = \"mlp-training/saved_models/model-800.ckpt\"\n",
    "size_mlp_data = (100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(num):\n",
    "    if num > 0:\n",
    "        return num\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def expansion(o_img,bbox,rate):\n",
    "    img = o_img.copy()\n",
    "    width = bbox[1] - bbox[0]\n",
    "    height = bbox[3] - bbox[2]\n",
    "    center = [bbox[0]+width/2,bbox[2]+height/2]\n",
    "    \n",
    "    new_bbox = [relu(round(center[0] - (width/2)*rate)), \\\n",
    "                relu(round(center[0] + (width/2)*rate)), \\\n",
    "                relu(round(center[1] - (height/2)*rate)), \\\n",
    "                relu(round(center[1] + (height/2)*rate)) ]\n",
    "    img = img[new_bbox[2]:new_bbox[3], new_bbox[0]:new_bbox[1]]\n",
    "    #print(center)\n",
    "    #print(new_bbox)\n",
    "    return img\n",
    "\n",
    "def get_yolo_info(imgcv):\n",
    "    result = tfnet.return_predict(imgcv)\n",
    "    if len(result) != 0:\n",
    "        result = result[0]\n",
    "        info = {'xmin':result[\"topleft\"][\"x\"],\n",
    "                'xmax':result[\"bottomright\"][\"x\"],\n",
    "                'ymin':result[\"topleft\"][\"y\"],\n",
    "                'ymax':result[\"bottomright\"][\"y\"],\n",
    "                'label':result[\"label\"]\n",
    "               }\n",
    "        return info\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def pre_mlp(o_img,info,expansion_rate):\n",
    "    #img = img[info['ymin']:info['ymax'],info['xmin']:info['xmax']]\n",
    "    img = expansion(o_img, [info['xmin'],info['xmax'], info['ymin'], info['ymax']], expansion_rate)\n",
    "    #img = expansion(img, [info['xmin'],info['xmax'], img.shape[0]-info['ymax'], img.shape[0]-info['ymin']], expansion_rate)\n",
    "    return img\n",
    "\n",
    "def draw(img,info):\n",
    "    output = img.copy()\n",
    "    cv2.rectangle(output, (info['xmin'], info['ymin']), (info['xmax'], info['ymax']), (0,0,255),2)\n",
    "    text_x, text_y = info['xmax']+10 , info['ymin']+10 \n",
    "    cv2.putText(output, info['label'], (text_x, text_y),cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    return output\n",
    "\n",
    "def detect(imgcv):\n",
    "    result = tfnet.return_predict(imgcv)\n",
    "    #print(type(result[0][\"topleft\"][\"x\"]))\n",
    "    if len(result) != 0:\n",
    "        result = result[0]\n",
    "        cv2.rectangle(imgcv, \n",
    "            (result[\"topleft\"][\"x\"], result[\"topleft\"][\"y\"]), \n",
    "            (result[\"bottomright\"][\"x\"], \n",
    "            result[\"bottomright\"][\"y\"]), \n",
    "            (0, 255, 0), 4)\n",
    "        text_x, text_y = result[\"topleft\"][\"x\"] - 10, result[\"topleft\"][\"y\"] - 10\n",
    "        cv2.putText(imgcv, result[\"label\"], (text_x, text_y),cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        #print(result)\n",
    "        # cv2.imshow('Test',imgcv)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        return imgcv\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP + YOLO Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(path_mlp_sample_image,0)\n",
    "img2 = cv2.resize(img, size_mlp_data)\n",
    "img2 = img2.flatten()\n",
    "print(img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuga\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "imv_csv = pd.read_csv(path_mlp_csv)\n",
    "class_y = pd.get_dummies(imv_csv['class'], '').as_matrix()#將label做 one_hot encoding\n",
    "x_train_list, y_train = imv_csv, class_y #資料切割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlp model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define placeholder ####\n",
    "input_data = tf.placeholder(dtype=tf.float32, \n",
    "                           shape=[None, img2.shape[0]],\n",
    "                           name='input_data') #用來接 feature 資料進入 tensorflow \n",
    "\n",
    "y_true = tf.placeholder(dtype=tf.float32, \n",
    "                        shape=[None, y_train.shape[1]],\n",
    "                        name='y_true') #用來接 label 資料進入 tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define variables(weight/bias) ####\n",
    "x1 = tf.layers.dense(input_data, 256, activation=tf.nn.sigmoid, name='hidden1') #第一層hidden layer\n",
    "x2 = tf.layers.dense(x1, 128, activation=tf.nn.sigmoid, name='hidden2') #第二層hidden layer\n",
    "x3 = tf.layers.dense(x2, 64, activation=tf.nn.sigmoid, name='hidden3')#第三層hidden layer\n",
    "out = tf.layers.dense(x3, y_train.shape[1], name='output')# output layer\n",
    "\n",
    "y_pred = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-1a333ea57121>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### calculate loss ####\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### optimize variables ####\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "update = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### init ####\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(10000, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden2/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden2/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden3/kernel:0' shape=(128, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'output/kernel:0' shape=(64, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'output/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables() ## 檢查 graph 裏的 global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlp load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from mlp-training/saved_models/model-800.ckpt\n"
     ]
    }
   ],
   "source": [
    "'''rerun the graph first:\n",
    "先回到上面將一開始和graph有關的cell先重新執行一遍，將graph架構先建立起來(這樣讀進來的參數才有對應位置存放)'''\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, path_mlp_model) #到我們剛剛存檔的路徑將檔案叫出來，放入graph中對應的參數位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(10000, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden2/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden2/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden3/kernel:0' shape=(128, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'output/kernel:0' shape=(64, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'output/bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing cfg/truck-yolo.cfg\n",
      "Loading None ...\n",
      "Finished in 0.0s\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 30)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.75 usage\n",
      "Loading from ./ckpt/truck-yolo-66000\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt/truck-yolo-66000\n",
      "Finished in 17.43934655189514s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main (YOLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.7820069204152249\n"
     ]
    }
   ],
   "source": [
    "yolo_predict = []\n",
    "for file in os.listdir(path_yolo_test):\n",
    "    img = cv2.imread(path_yolo_test+file)\n",
    "    imgcv = detect(img)\n",
    "    if len(imgcv) != 0:\n",
    "        yolo_predict.append(1)\n",
    "    else:\n",
    "        yolo_predict.append(0)\n",
    "#print(yolo_predict)\n",
    "print('f1-score:',f1_score(np.full((1,len(yolo_predict)),1)[0], yolo_predict,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "f1-score: 0.10441767068273092\n",
      "13 236\n",
      "誤差率: 5.508474576271187 %\n"
     ]
    }
   ],
   "source": [
    "yolo_predict = []\n",
    "for file in os.listdir(path_new):\n",
    "    img = cv2.imread(path_new+file)\n",
    "    imgcv = detect(img)\n",
    "    if len(imgcv) != 0:\n",
    "        yolo_predict.append(1)\n",
    "    else:\n",
    "        yolo_predict.append(0)\n",
    "#print(yolo_predict)\n",
    "#print('f1-score:',f1_score(np.full((1,len(yolo_predict)),1)[0], yolo_predict,average='binary'))\n",
    "#print(sum(yolo_predict), len(yolo_predict) )\n",
    "print(\"誤差率:\", 100*sum(yolo_predict)/len(yolo_predict) ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "timeF = 50\n",
    "path_all_video = \"../完整影片/\"\n",
    "path_save_folder = path_video_folder+'result/'\n",
    "file_list = os.listdir(path_video_folder)\n",
    "if not os.path.exists(path_save_folder):\n",
    "    os.makedirs(path_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cc2d12e8c0e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_video_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 以迴圈從影片檔案讀取影格，並顯示出來\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    cap = cv2.VideoCapture(path_video_folder+folder_name+file)\n",
    "    c = 0\n",
    "    # 以迴圈從影片檔案讀取影格，並顯示出來\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        if(c%timeF==0):\n",
    "            #print(type(frame))\n",
    "            origin = frame[35:,100:300]\n",
    "#             cv2.imshow('123',origin)\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "            imgcv = detect(origin)\n",
    "            if len(imgcv) != 0:\n",
    "                count += 1\n",
    "                cv2.imwrite(path_save_folder+file[:file.index('.')]+'.jpg',imgcv)\n",
    "            total += 1\n",
    "        c += 1\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Object detected files:',count,'/',total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main (MLP+YOLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_predict = []\n",
    "for file in os.listdir(path_yolo_test):\n",
    "    img = cv2.imread(path_yolo_test+file)\n",
    "    imgcv = detect(img)\n",
    "    if len(imgcv) != 0:\n",
    "        yolo_predict.append(1)\n",
    "    else:\n",
    "        yolo_predict.append(0)\n",
    "#print(yolo_predict)\n",
    "print('f1-score:',f1_score(np.full((1,len(yolo_predict)),1)[0], yolo_predict,average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'normal_detect':0,'normal_undetect':0,'abnormal_detect':0,'abnormal_undetect':0}\n",
    "correct = 0\n",
    "total_result = [0,0,0,0]\n",
    "data_number = 1000\n",
    "tmp = os.listdir(path_cellphone)\n",
    "dir_list = []\n",
    "for i in range(len(tmp)):\n",
    "    if 'jpg' in tmp[i]:\n",
    "        dir_list.append(tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in dir_list:\n",
    "#     img = cv2.imread(path_test_data+file)\n",
    "#     img = detect(img)\n",
    "#     if len(img) !=0:\n",
    "#         #print(yolo_info)\n",
    "#         cv2.imwrite(path_original+file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.jpg',\n",
       " '1.jpg',\n",
       " '10.jpg',\n",
       " '100.jpg',\n",
       " '101.jpg',\n",
       " '102.jpg',\n",
       " '103.jpg',\n",
       " '104.jpg',\n",
       " '105.jpg',\n",
       " '106.jpg',\n",
       " '107.jpg',\n",
       " '108.jpg',\n",
       " '109.jpg',\n",
       " '11.jpg',\n",
       " '110.jpg',\n",
       " '111.jpg',\n",
       " '112.jpg',\n",
       " '113.jpg',\n",
       " '114.jpg',\n",
       " '115.jpg',\n",
       " '116.jpg',\n",
       " '117.jpg',\n",
       " '118.jpg',\n",
       " '119.jpg',\n",
       " '12.jpg',\n",
       " '120.jpg',\n",
       " '121.jpg',\n",
       " '122.jpg',\n",
       " '123.jpg',\n",
       " '124.jpg',\n",
       " '125.jpg',\n",
       " '126.jpg',\n",
       " '127.jpg',\n",
       " '128.jpg',\n",
       " '129.jpg',\n",
       " '13.jpg',\n",
       " '130.jpg',\n",
       " '131.jpg',\n",
       " '132.jpg',\n",
       " '133.jpg',\n",
       " '134.jpg',\n",
       " '135.jpg',\n",
       " '136.jpg',\n",
       " '137.jpg',\n",
       " '138.jpg',\n",
       " '139.jpg',\n",
       " '14.jpg',\n",
       " '140.jpg',\n",
       " '141.jpg',\n",
       " '142.jpg',\n",
       " '143.jpg',\n",
       " '144.jpg',\n",
       " '145.jpg',\n",
       " '146.jpg',\n",
       " '147.jpg',\n",
       " '148.jpg',\n",
       " '149.jpg',\n",
       " '15.jpg',\n",
       " '150.jpg',\n",
       " '151.jpg',\n",
       " '152.jpg',\n",
       " '153.jpg',\n",
       " '154.jpg',\n",
       " '155.jpg',\n",
       " '156.jpg',\n",
       " '157.jpg',\n",
       " '158.jpg',\n",
       " '159.jpg',\n",
       " '16.jpg',\n",
       " '160.jpg',\n",
       " '161.jpg',\n",
       " '162.jpg',\n",
       " '163.jpg',\n",
       " '164.jpg',\n",
       " '165.jpg',\n",
       " '166.jpg',\n",
       " '167.jpg',\n",
       " '168.jpg',\n",
       " '169.jpg',\n",
       " '17.jpg',\n",
       " '170.jpg',\n",
       " '171.jpg',\n",
       " '172.jpg',\n",
       " '173.jpg',\n",
       " '174.jpg',\n",
       " '175.jpg',\n",
       " '18.jpg',\n",
       " '19.jpg',\n",
       " '2.jpg',\n",
       " '20.jpg',\n",
       " '21.jpg',\n",
       " '22.jpg',\n",
       " '23.jpg',\n",
       " '24.jpg',\n",
       " '25.jpg',\n",
       " '26.jpg',\n",
       " '27.jpg',\n",
       " '28.jpg',\n",
       " '29.jpg',\n",
       " '3.jpg',\n",
       " '30.jpg',\n",
       " '31.jpg',\n",
       " '32.jpg',\n",
       " '33.jpg',\n",
       " '34.jpg',\n",
       " '35.jpg',\n",
       " '36.jpg',\n",
       " '37.jpg',\n",
       " '38.jpg',\n",
       " '39.jpg',\n",
       " '4.jpg',\n",
       " '40.jpg',\n",
       " '41.jpg',\n",
       " '42.jpg',\n",
       " '43.jpg',\n",
       " '44.jpg',\n",
       " '45.jpg',\n",
       " '46.jpg',\n",
       " '47.jpg',\n",
       " '48.jpg',\n",
       " '49.jpg',\n",
       " '5.jpg',\n",
       " '50.jpg',\n",
       " '51.jpg',\n",
       " '52.jpg',\n",
       " '53.jpg',\n",
       " '54.jpg',\n",
       " '55.jpg',\n",
       " '56.jpg',\n",
       " '57.jpg',\n",
       " '58.jpg',\n",
       " '59.jpg',\n",
       " '6.jpg',\n",
       " '60.jpg',\n",
       " '61.jpg',\n",
       " '62.jpg',\n",
       " '63.jpg',\n",
       " '64.jpg',\n",
       " '65.jpg',\n",
       " '66.jpg',\n",
       " '67.jpg',\n",
       " '68.jpg',\n",
       " '69.jpg',\n",
       " '7.jpg',\n",
       " '70.jpg',\n",
       " '71.jpg',\n",
       " '72.jpg',\n",
       " '73.jpg',\n",
       " '74.jpg',\n",
       " '75.jpg',\n",
       " '76.jpg',\n",
       " '77.jpg',\n",
       " '78.jpg',\n",
       " '79.jpg',\n",
       " '8.jpg',\n",
       " '80.jpg',\n",
       " '81.jpg',\n",
       " '82.jpg',\n",
       " '83.jpg',\n",
       " '84.jpg',\n",
       " '85.jpg',\n",
       " '86.jpg',\n",
       " '87.jpg',\n",
       " '88.jpg',\n",
       " '89.jpg',\n",
       " '9.jpg',\n",
       " '90.jpg',\n",
       " '91.jpg',\n",
       " '92.jpg',\n",
       " '93.jpg',\n",
       " '94.jpg',\n",
       " '95.jpg',\n",
       " '96.jpg',\n",
       " '97.jpg',\n",
       " '98.jpg',\n",
       " '99.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg {'xmin': 328, 'xmax': 375, 'ymin': 261, 'ymax': 308, 'label': 'cellphone'}\n",
      "[array([[ 1.9116882, -2.1895523]], dtype=float32)]\n",
      "1.jpg {'xmin': 328, 'xmax': 375, 'ymin': 261, 'ymax': 308, 'label': 'cellphone'}\n",
      "[array([[ 1.9143988, -2.1919494]], dtype=float32)]\n",
      "10.jpg {'xmin': 90, 'xmax': 136, 'ymin': 370, 'ymax': 430, 'label': 'cellphone'}\n",
      "[array([[ 0.08121147, -0.56160843]], dtype=float32)]\n",
      "100.jpg {'xmin': 278, 'xmax': 326, 'ymin': 208, 'ymax': 256, 'label': 'cellphone'}\n",
      "[array([[ 1.0706854, -1.4375196]], dtype=float32)]\n",
      "101.jpg {'xmin': 278, 'xmax': 326, 'ymin': 217, 'ymax': 264, 'label': 'cellphone'}\n",
      "[array([[-0.03508101, -0.46273607]], dtype=float32)]\n",
      "102.jpg {'xmin': 129, 'xmax': 173, 'ymin': 340, 'ymax': 416, 'label': 'cellphone'}\n",
      "[array([[ 2.2652695, -2.4942844]], dtype=float32)]\n",
      "103.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 424, 'label': 'cellphone'}\n",
      "[array([[ 2.39477 , -2.613116]], dtype=float32)]\n",
      "104.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 423, 'label': 'cellphone'}\n",
      "[array([[ 2.4625413, -2.6729968]], dtype=float32)]\n",
      "105.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 424, 'label': 'cellphone'}\n",
      "[array([[ 2.4307323, -2.6450973]], dtype=float32)]\n",
      "106.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 424, 'label': 'cellphone'}\n",
      "[array([[ 2.4045556, -2.6226358]], dtype=float32)]\n",
      "107.jpg {'xmin': 328, 'xmax': 374, 'ymin': 121, 'ymax': 165, 'label': 'cellphone'}\n",
      "[array([[ 3.6586273, -3.731489 ]], dtype=float32)]\n",
      "108.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 424, 'label': 'cellphone'}\n",
      "[array([[ 2.417869 , -2.6337097]], dtype=float32)]\n",
      "109.jpg {'xmin': 127, 'xmax': 171, 'ymin': 346, 'ymax': 424, 'label': 'cellphone'}\n",
      "[array([[ 2.3880649, -2.6073444]], dtype=float32)]\n",
      "110.jpg {'xmin': 446, 'xmax': 488, 'ymin': 567, 'ymax': 607, 'label': 'cellphone'}\n",
      "[array([[ 1.3532888, -1.6832798]], dtype=float32)]\n",
      "111.jpg {'xmin': 249, 'xmax': 297, 'ymin': 513, 'ymax': 562, 'label': 'cellphone'}\n",
      "[array([[ 1.0755403, -1.4438374]], dtype=float32)]\n",
      "112.jpg {'xmin': 345, 'xmax': 387, 'ymin': 131, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 3.5667434, -3.642338 ]], dtype=float32)]\n",
      "113.jpg {'xmin': 399, 'xmax': 439, 'ymin': 266, 'ymax': 304, 'label': 'cellphone'}\n",
      "[array([[ 1.4035015, -1.7338536]], dtype=float32)]\n",
      "114.jpg {'xmin': 403, 'xmax': 440, 'ymin': 289, 'ymax': 326, 'label': 'cellphone'}\n",
      "[array([[ 1.0556738, -1.426919 ]], dtype=float32)]\n",
      "115.jpg {'xmin': 387, 'xmax': 429, 'ymin': 285, 'ymax': 328, 'label': 'cellphone'}\n",
      "[array([[ 1.472599, -1.798584]], dtype=float32)]\n",
      "116.jpg {'xmin': 352, 'xmax': 395, 'ymin': 366, 'ymax': 411, 'label': 'cellphone'}\n",
      "[array([[ 0.90814054, -1.2993443 ]], dtype=float32)]\n",
      "117.jpg {'xmin': 220, 'xmax': 268, 'ymin': 506, 'ymax': 554, 'label': 'cellphone'}\n",
      "[array([[ 1.2042232, -1.558748 ]], dtype=float32)]\n",
      "118.jpg {'xmin': 219, 'xmax': 267, 'ymin': 506, 'ymax': 555, 'label': 'cellphone'}\n",
      "[array([[ 1.043876 , -1.4156036]], dtype=float32)]\n",
      "119.jpg {'xmin': 221, 'xmax': 267, 'ymin': 507, 'ymax': 554, 'label': 'cellphone'}\n",
      "[array([[ 0.8324541, -1.2279686]], dtype=float32)]\n",
      "12.jpg {'xmin': 87, 'xmax': 134, 'ymin': 371, 'ymax': 430, 'label': 'cellphone'}\n",
      "[array([[ 0.0828048, -0.5647   ]], dtype=float32)]\n",
      "120.jpg {'xmin': 345, 'xmax': 386, 'ymin': 136, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 4.14966  , -4.1643953]], dtype=float32)]\n",
      "121.jpg {'xmin': 221, 'xmax': 267, 'ymin': 507, 'ymax': 555, 'label': 'cellphone'}\n",
      "[array([[ 0.56215435, -0.9885715 ]], dtype=float32)]\n",
      "122.jpg {'xmin': 343, 'xmax': 392, 'ymin': 265, 'ymax': 314, 'label': 'cellphone'}\n",
      "[array([[-0.24748877, -0.27873686]], dtype=float32)]\n",
      "123.jpg {'xmin': 345, 'xmax': 385, 'ymin': 137, 'ymax': 174, 'label': 'cellphone'}\n",
      "[array([[ 3.796891 , -3.8525088]], dtype=float32)]\n",
      "124.jpg {'xmin': 347, 'xmax': 389, 'ymin': 137, 'ymax': 175, 'label': 'cellphone'}\n",
      "[array([[ 3.6981487, -3.7635796]], dtype=float32)]\n",
      "125.jpg {'xmin': 342, 'xmax': 383, 'ymin': 135, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 4.1544905, -4.167569 ]], dtype=float32)]\n",
      "126.jpg {'xmin': 344, 'xmax': 384, 'ymin': 139, 'ymax': 175, 'label': 'cellphone'}\n",
      "[array([[ 3.7622223, -3.823299 ]], dtype=float32)]\n",
      "127.jpg {'xmin': 346, 'xmax': 385, 'ymin': 135, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 3.6077569, -3.6840398]], dtype=float32)]\n",
      "128.jpg {'xmin': 343, 'xmax': 383, 'ymin': 137, 'ymax': 174, 'label': 'cellphone'}\n",
      "[array([[ 3.6705446, -3.7398696]], dtype=float32)]\n",
      "129.jpg {'xmin': 340, 'xmax': 381, 'ymin': 133, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 4.114626 , -4.1312637]], dtype=float32)]\n",
      "13.jpg {'xmin': 277, 'xmax': 326, 'ymin': 227, 'ymax': 276, 'label': 'cellphone'}\n",
      "[array([[-0.20220408, -0.31598455]], dtype=float32)]\n",
      "130.jpg {'xmin': 346, 'xmax': 386, 'ymin': 136, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 3.8596623, -3.9071283]], dtype=float32)]\n",
      "131.jpg {'xmin': 341, 'xmax': 382, 'ymin': 135, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 3.9655352, -3.9990766]], dtype=float32)]\n",
      "132.jpg {'xmin': 349, 'xmax': 389, 'ymin': 142, 'ymax': 178, 'label': 'cellphone'}\n",
      "[array([[ 3.35892  , -3.4649591]], dtype=float32)]\n",
      "133.jpg {'xmin': 335, 'xmax': 378, 'ymin': 134, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 3.564118, -3.644354]], dtype=float32)]\n",
      "134.jpg {'xmin': 341, 'xmax': 382, 'ymin': 134, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 4.1052885, -4.122505 ]], dtype=float32)]\n",
      "135.jpg {'xmin': 344, 'xmax': 385, 'ymin': 137, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 3.7500987, -3.809896 ]], dtype=float32)]\n",
      "136.jpg {'xmin': 344, 'xmax': 385, 'ymin': 139, 'ymax': 175, 'label': 'cellphone'}\n",
      "[array([[ 3.6835577, -3.7531753]], dtype=float32)]\n",
      "137.jpg {'xmin': 342, 'xmax': 382, 'ymin': 139, 'ymax': 175, 'label': 'cellphone'}\n",
      "[array([[ 3.668788, -3.740387]], dtype=float32)]\n",
      "138.jpg {'xmin': 342, 'xmax': 383, 'ymin': 133, 'ymax': 172, 'label': 'cellphone'}\n",
      "[array([[ 4.098098 , -4.1168776]], dtype=float32)]\n",
      "139.jpg {'xmin': 346, 'xmax': 385, 'ymin': 141, 'ymax': 176, 'label': 'cellphone'}\n",
      "[array([[ 3.0909424, -3.2274072]], dtype=float32)]\n",
      "140.jpg {'xmin': 342, 'xmax': 383, 'ymin': 140, 'ymax': 176, 'label': 'cellphone'}\n",
      "[array([[ 3.6084483, -3.6864247]], dtype=float32)]\n",
      "141.jpg {'xmin': 350, 'xmax': 390, 'ymin': 141, 'ymax': 177, 'label': 'cellphone'}\n",
      "[array([[ 3.4888144, -3.5792282]], dtype=float32)]\n",
      "142.jpg {'xmin': 340, 'xmax': 380, 'ymin': 138, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 3.5866828, -3.6634347]], dtype=float32)]\n",
      "143.jpg {'xmin': 345, 'xmax': 384, 'ymin': 139, 'ymax': 174, 'label': 'cellphone'}\n",
      "[array([[ 3.820142 , -3.8729808]], dtype=float32)]\n",
      "144.jpg {'xmin': 285, 'xmax': 327, 'ymin': 138, 'ymax': 178, 'label': 'cellphone'}\n",
      "[array([[ 0.4264438, -0.8617867]], dtype=float32)]\n",
      "146.jpg {'xmin': 283, 'xmax': 326, 'ymin': 136, 'ymax': 179, 'label': 'cellphone'}\n",
      "147.jpg {'xmin': 266, 'xmax': 307, 'ymin': 67, 'ymax': 108, 'label': 'cellphone'}\n",
      "[array([[ 2.8587792, -3.0219069]], dtype=float32)]\n",
      "148.jpg {'xmin': 284, 'xmax': 331, 'ymin': 103, 'ymax': 151, 'label': 'cellphone'}\n",
      "[array([[ 3.1020906, -3.2428427]], dtype=float32)]\n",
      "149.jpg {'xmin': 292, 'xmax': 339, 'ymin': 118, 'ymax': 166, 'label': 'cellphone'}\n",
      "[array([[ 3.4341185, -3.5272   ]], dtype=float32)]\n",
      "152.jpg {'xmin': 306, 'xmax': 349, 'ymin': 110, 'ymax': 149, 'label': 'cellphone'}\n",
      "[array([[ 3.1385958, -3.269729 ]], dtype=float32)]\n",
      "153.jpg {'xmin': 305, 'xmax': 350, 'ymin': 120, 'ymax': 161, 'label': 'cellphone'}\n",
      "[array([[ 3.0239675, -3.1666377]], dtype=float32)]\n",
      "154.jpg {'xmin': 313, 'xmax': 357, 'ymin': 118, 'ymax': 157, 'label': 'cellphone'}\n",
      "[array([[ 2.7754598, -2.9503038]], dtype=float32)]\n",
      "155.jpg {'xmin': 337, 'xmax': 379, 'ymin': 135, 'ymax': 176, 'label': 'cellphone'}\n",
      "[array([[ 4.4746675, -4.4404926]], dtype=float32)]\n",
      "156.jpg {'xmin': 332, 'xmax': 377, 'ymin': 127, 'ymax': 174, 'label': 'cellphone'}\n",
      "[array([[ 1.672161 , -1.9644694]], dtype=float32)]\n",
      "157.jpg {'xmin': 332, 'xmax': 376, 'ymin': 120, 'ymax': 161, 'label': 'cellphone'}\n",
      "[array([[ 2.2240827, -2.4631338]], dtype=float32)]\n",
      "161.jpg {'xmin': 344, 'xmax': 390, 'ymin': 121, 'ymax': 165, 'label': 'cellphone'}\n",
      "[array([[ 2.577479 , -2.7803478]], dtype=float32)]\n",
      "162.jpg {'xmin': 348, 'xmax': 396, 'ymin': 121, 'ymax': 167, 'label': 'cellphone'}\n",
      "[array([[ 3.0554698, -3.2021499]], dtype=float32)]\n",
      "163.jpg {'xmin': 349, 'xmax': 395, 'ymin': 126, 'ymax': 165, 'label': 'cellphone'}\n",
      "[array([[ 1.5725653, -1.877352 ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.jpg {'xmin': 345, 'xmax': 392, 'ymin': 123, 'ymax': 167, 'label': 'cellphone'}\n",
      "[array([[ 3.7086294, -3.7741778]], dtype=float32)]\n",
      "165.jpg {'xmin': 342, 'xmax': 386, 'ymin': 125, 'ymax': 164, 'label': 'cellphone'}\n",
      "[array([[ 3.4719007, -3.5729043]], dtype=float32)]\n",
      "166.jpg {'xmin': 345, 'xmax': 384, 'ymin': 136, 'ymax': 173, 'label': 'cellphone'}\n",
      "[array([[ 3.5403588, -3.6273348]], dtype=float32)]\n",
      "169.jpg {'xmin': 196, 'xmax': 241, 'ymin': 339, 'ymax': 386, 'label': 'cellphone'}\n",
      "[array([[ 1.05442  , -1.4251102]], dtype=float32)]\n",
      "170.jpg {'xmin': 129, 'xmax': 173, 'ymin': 361, 'ymax': 447, 'label': 'cellphone'}\n",
      "[array([[ 0.7113157, -1.1210455]], dtype=float32)]\n",
      "171.jpg {'xmin': 303, 'xmax': 350, 'ymin': 174, 'ymax': 220, 'label': 'cellphone'}\n",
      "[array([[ 2.0632012, -2.3224854]], dtype=float32)]\n",
      "172.jpg {'xmin': 126, 'xmax': 168, 'ymin': 344, 'ymax': 429, 'label': 'cellphone'}\n",
      "[array([[ 1.5282097, -1.8436666]], dtype=float32)]\n",
      "173.jpg {'xmin': 123, 'xmax': 166, 'ymin': 356, 'ymax': 446, 'label': 'cellphone'}\n",
      "[array([[ 1.983146 , -2.2515395]], dtype=float32)]\n",
      "174.jpg {'xmin': 123, 'xmax': 166, 'ymin': 356, 'ymax': 445, 'label': 'cellphone'}\n",
      "[array([[ 2.082659 , -2.3383632]], dtype=float32)]\n",
      "175.jpg {'xmin': 123, 'xmax': 165, 'ymin': 357, 'ymax': 446, 'label': 'cellphone'}\n",
      "[array([[ 1.7935793, -2.082626 ]], dtype=float32)]\n",
      "18.jpg {'xmin': 306, 'xmax': 349, 'ymin': 195, 'ymax': 233, 'label': 'cellphone'}\n",
      "[array([[ 3.6739328, -3.7452633]], dtype=float32)]\n",
      "19.jpg {'xmin': 124, 'xmax': 168, 'ymin': 354, 'ymax': 441, 'label': 'cellphone'}\n",
      "[array([[ 1.6516763, -1.9548796]], dtype=float32)]\n",
      "2.jpg {'xmin': 92, 'xmax': 139, 'ymin': 373, 'ymax': 432, 'label': 'cellphone'}\n",
      "[array([[ 0.8562942, -1.2489904]], dtype=float32)]\n",
      "20.jpg {'xmin': 127, 'xmax': 170, 'ymin': 354, 'ymax': 439, 'label': 'cellphone'}\n",
      "[array([[ 1.1565953, -1.5172257]], dtype=float32)]\n",
      "21.jpg {'xmin': 127, 'xmax': 170, 'ymin': 352, 'ymax': 438, 'label': 'cellphone'}\n",
      "[array([[ 1.3811619, -1.7144322]], dtype=float32)]\n",
      "22.jpg {'xmin': 124, 'xmax': 167, 'ymin': 354, 'ymax': 441, 'label': 'cellphone'}\n",
      "[array([[ 1.3777281, -1.7102963]], dtype=float32)]\n",
      "23.jpg {'xmin': 124, 'xmax': 168, 'ymin': 352, 'ymax': 437, 'label': 'cellphone'}\n",
      "[array([[ 1.7335863, -2.0173154]], dtype=float32)]\n",
      "27.jpg {'xmin': 293, 'xmax': 339, 'ymin': 195, 'ymax': 235, 'label': 'cellphone'}\n",
      "[array([[ 2.120795 , -2.3740265]], dtype=float32)]\n",
      "28.jpg {'xmin': 296, 'xmax': 341, 'ymin': 187, 'ymax': 228, 'label': 'cellphone'}\n",
      "[array([[ 3.1503966, -3.282385 ]], dtype=float32)]\n",
      "29.jpg {'xmin': 124, 'xmax': 166, 'ymin': 352, 'ymax': 441, 'label': 'cellphone'}\n",
      "[array([[ 1.786304 , -2.0732853]], dtype=float32)]\n",
      "3.jpg {'xmin': 93, 'xmax': 140, 'ymin': 373, 'ymax': 431, 'label': 'cellphone'}\n",
      "[array([[ 1.5199585, -1.8382139]], dtype=float32)]\n",
      "30.jpg {'xmin': 123, 'xmax': 166, 'ymin': 358, 'ymax': 447, 'label': 'cellphone'}\n",
      "[array([[ 2.8272622, -2.9988718]], dtype=float32)]\n",
      "31.jpg {'xmin': 123, 'xmax': 166, 'ymin': 358, 'ymax': 447, 'label': 'cellphone'}\n",
      "[array([[ 2.86021  , -3.0278842]], dtype=float32)]\n",
      "32.jpg {'xmin': 306, 'xmax': 354, 'ymin': 197, 'ymax': 242, 'label': 'cellphone'}\n",
      "[array([[ 2.8819194, -3.0456104]], dtype=float32)]\n",
      "34.jpg {'xmin': 312, 'xmax': 355, 'ymin': 112, 'ymax': 153, 'label': 'cellphone'}\n",
      "[array([[ 2.2456326, -2.479338 ]], dtype=float32)]\n",
      "35.jpg {'xmin': 308, 'xmax': 355, 'ymin': 105, 'ymax': 151, 'label': 'cellphone'}\n",
      "[array([[ 2.9942522, -3.1410983]], dtype=float32)]\n",
      "36.jpg {'xmin': 342, 'xmax': 387, 'ymin': 140, 'ymax': 180, 'label': 'cellphone'}\n",
      "[array([[ 4.0892987, -4.113429 ]], dtype=float32)]\n",
      "37.jpg {'xmin': 306, 'xmax': 352, 'ymin': 107, 'ymax': 151, 'label': 'cellphone'}\n",
      "[array([[ 3.015941 , -3.1660461]], dtype=float32)]\n",
      "4.jpg {'xmin': 92, 'xmax': 139, 'ymin': 373, 'ymax': 432, 'label': 'cellphone'}\n",
      "[array([[ 0.9285088, -1.3129395]], dtype=float32)]\n",
      "42.jpg {'xmin': 256, 'xmax': 301, 'ymin': 267, 'ymax': 344, 'label': 'cellphone'}\n",
      "[array([[ 2.3485334, -2.5700173]], dtype=float32)]\n",
      "44.jpg {'xmin': 345, 'xmax': 390, 'ymin': 142, 'ymax': 183, 'label': 'cellphone'}\n",
      "[array([[ 3.9000196, -3.9458544]], dtype=float32)]\n",
      "46.jpg {'xmin': 258, 'xmax': 301, 'ymin': 263, 'ymax': 343, 'label': 'cellphone'}\n",
      "[array([[ 2.2723658, -2.5042322]], dtype=float32)]\n",
      "47.jpg {'xmin': 257, 'xmax': 301, 'ymin': 263, 'ymax': 345, 'label': 'cellphone'}\n",
      "[array([[ 2.0688236, -2.3240001]], dtype=float32)]\n",
      "48.jpg {'xmin': 257, 'xmax': 301, 'ymin': 263, 'ymax': 345, 'label': 'cellphone'}\n",
      "[array([[ 2.081611, -2.334966]], dtype=float32)]\n",
      "5.jpg {'xmin': 93, 'xmax': 140, 'ymin': 373, 'ymax': 431, 'label': 'cellphone'}\n",
      "[array([[ 1.5182407, -1.8367814]], dtype=float32)]\n",
      "52.jpg {'xmin': 347, 'xmax': 393, 'ymin': 149, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 1.6164063, -1.9294593]], dtype=float32)]\n",
      "53.jpg {'xmin': 256, 'xmax': 300, 'ymin': 262, 'ymax': 345, 'label': 'cellphone'}\n",
      "[array([[ 1.8759606, -2.1571424]], dtype=float32)]\n",
      "54.jpg {'xmin': 330, 'xmax': 372, 'ymin': 160, 'ymax': 196, 'label': 'cellphone'}\n",
      "[array([[ 0.7964383, -1.1973426]], dtype=float32)]\n",
      "55.jpg {'xmin': 328, 'xmax': 372, 'ymin': 161, 'ymax': 200, 'label': 'cellphone'}\n",
      "[array([[ 1.5493277, -1.8702657]], dtype=float32)]\n",
      "56.jpg {'xmin': 344, 'xmax': 386, 'ymin': 151, 'ymax': 187, 'label': 'cellphone'}\n",
      "[array([[ 1.3821744, -1.7183095]], dtype=float32)]\n",
      "58.jpg {'xmin': 350, 'xmax': 395, 'ymin': 142, 'ymax': 184, 'label': 'cellphone'}\n",
      "[array([[ 4.039043, -4.070552]], dtype=float32)]\n",
      "59.jpg {'xmin': 334, 'xmax': 377, 'ymin': 160, 'ymax': 197, 'label': 'cellphone'}\n",
      "[array([[ 1.5282333, -1.8460364]], dtype=float32)]\n",
      "6.jpg {'xmin': 93, 'xmax': 140, 'ymin': 374, 'ymax': 430, 'label': 'cellphone'}\n",
      "[array([[ 2.5144334, -2.7165556]], dtype=float32)]\n",
      "60.jpg {'xmin': 335, 'xmax': 379, 'ymin': 156, 'ymax': 193, 'label': 'cellphone'}\n",
      "[array([[ 1.7647672, -2.0564516]], dtype=float32)]\n",
      "61.jpg {'xmin': 344, 'xmax': 385, 'ymin': 155, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 2.6897228, -2.876865 ]], dtype=float32)]\n",
      "62.jpg {'xmin': 333, 'xmax': 376, 'ymin': 156, 'ymax': 194, 'label': 'cellphone'}\n",
      "[array([[ 2.3535633, -2.5816655]], dtype=float32)]\n",
      "64.jpg {'xmin': 337, 'xmax': 378, 'ymin': 154, 'ymax': 190, 'label': 'cellphone'}\n",
      "65.jpg {'xmin': 338, 'xmax': 382, 'ymin': 150, 'ymax': 188, 'label': 'cellphone'}\n",
      "[array([[ 2.949912, -3.104298]], dtype=float32)]\n",
      "66.jpg {'xmin': 330, 'xmax': 372, 'ymin': 153, 'ymax': 191, 'label': 'cellphone'}\n",
      "[array([[ 1.4797796, -1.8000283]], dtype=float32)]\n",
      "67.jpg {'xmin': 351, 'xmax': 395, 'ymin': 147, 'ymax': 186, 'label': 'cellphone'}\n",
      "[array([[ 2.2732706, -2.5043733]], dtype=float32)]\n",
      "68.jpg {'xmin': 333, 'xmax': 379, 'ymin': 148, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 4.048207 , -4.0809345]], dtype=float32)]\n",
      "69.jpg {'xmin': 317, 'xmax': 365, 'ymin': 156, 'ymax': 201, 'label': 'cellphone'}\n",
      "[array([[ 2.7465289, -2.9308324]], dtype=float32)]\n",
      "7.jpg {'xmin': 94, 'xmax': 140, 'ymin': 374, 'ymax': 429, 'label': 'cellphone'}\n",
      "[array([[ 2.2894151, -2.51581  ]], dtype=float32)]\n",
      "70.jpg {'xmin': 107, 'xmax': 148, 'ymin': 270, 'ymax': 310, 'label': 'cellphone'}\n",
      "[array([[ 0.9876407, -1.3733351]], dtype=float32)]\n",
      "71.jpg {'xmin': 107, 'xmax': 149, 'ymin': 270, 'ymax': 311, 'label': 'cellphone'}\n",
      "[array([[ 0.70298517, -1.1168385 ]], dtype=float32)]\n",
      "72.jpg {'xmin': 107, 'xmax': 149, 'ymin': 270, 'ymax': 311, 'label': 'cellphone'}\n",
      "[array([[ 0.80611825, -1.2086407 ]], dtype=float32)]\n",
      "73.jpg {'xmin': 343, 'xmax': 386, 'ymin': 144, 'ymax': 181, 'label': 'cellphone'}\n",
      "[array([[ 3.6877482, -3.76083  ]], dtype=float32)]\n",
      "74.jpg {'xmin': 107, 'xmax': 149, 'ymin': 271, 'ymax': 311, 'label': 'cellphone'}\n",
      "[array([[ 0.640471 , -1.0619365]], dtype=float32)]\n",
      "75.jpg {'xmin': 107, 'xmax': 150, 'ymin': 271, 'ymax': 312, 'label': 'cellphone'}\n",
      "[array([[ 1.093756 , -1.4634286]], dtype=float32)]\n",
      "76.jpg {'xmin': 107, 'xmax': 146, 'ymin': 271, 'ymax': 311, 'label': 'cellphone'}\n",
      "[array([[ 1.7179343, -2.013125 ]], dtype=float32)]\n",
      "77.jpg {'xmin': 335, 'xmax': 376, 'ymin': 149, 'ymax': 184, 'label': 'cellphone'}\n",
      "[array([[ 2.3293312, -2.5553677]], dtype=float32)]\n",
      "78.jpg {'xmin': 327, 'xmax': 371, 'ymin': 153, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 2.521277 , -2.7258506]], dtype=float32)]\n",
      "79.jpg {'xmin': 319, 'xmax': 364, 'ymin': 156, 'ymax': 195, 'label': 'cellphone'}\n",
      "[array([[ 0.0470442, -0.5300741]], dtype=float32)]\n",
      "8.jpg {'xmin': 93, 'xmax': 140, 'ymin': 374, 'ymax': 429, 'label': 'cellphone'}\n",
      "[array([[ 2.3699188, -2.5875454]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.jpg {'xmin': 346, 'xmax': 389, 'ymin': 147, 'ymax': 185, 'label': 'cellphone'}\n",
      "[array([[ 2.31152  , -2.5423663]], dtype=float32)]\n",
      "81.jpg {'xmin': 330, 'xmax': 374, 'ymin': 159, 'ymax': 197, 'label': 'cellphone'}\n",
      "[array([[ 1.8252276, -2.1129835]], dtype=float32)]\n",
      "82.jpg {'xmin': 349, 'xmax': 387, 'ymin': 158, 'ymax': 192, 'label': 'cellphone'}\n",
      "[array([[ 1.0940379, -1.4645603]], dtype=float32)]\n",
      "83.jpg {'xmin': 349, 'xmax': 389, 'ymin': 155, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 0.73658335, -1.14241   ]], dtype=float32)]\n",
      "84.jpg {'xmin': 344, 'xmax': 384, 'ymin': 158, 'ymax': 192, 'label': 'cellphone'}\n",
      "[array([[ 0.11543451, -0.5955532 ]], dtype=float32)]\n",
      "85.jpg {'xmin': 334, 'xmax': 377, 'ymin': 159, 'ymax': 195, 'label': 'cellphone'}\n",
      "[array([[ 0.71147233, -1.1194191 ]], dtype=float32)]\n",
      "86.jpg {'xmin': 332, 'xmax': 375, 'ymin': 161, 'ymax': 197, 'label': 'cellphone'}\n",
      "[array([[ 1.655963 , -1.9559885]], dtype=float32)]\n",
      "87.jpg {'xmin': 334, 'xmax': 377, 'ymin': 161, 'ymax': 199, 'label': 'cellphone'}\n",
      "[array([[ 1.7414213, -2.0291362]], dtype=float32)]\n",
      "88.jpg {'xmin': 342, 'xmax': 380, 'ymin': 158, 'ymax': 191, 'label': 'cellphone'}\n",
      "89.jpg {'xmin': 336, 'xmax': 380, 'ymin': 159, 'ymax': 195, 'label': 'cellphone'}\n",
      "[array([[ 0.00254548, -0.48909274]], dtype=float32)]\n",
      "9.jpg {'xmin': 91, 'xmax': 138, 'ymin': 373, 'ymax': 432, 'label': 'cellphone'}\n",
      "[array([[ 1.7026911, -1.9990189]], dtype=float32)]\n",
      "90.jpg {'xmin': 334, 'xmax': 378, 'ymin': 159, 'ymax': 197, 'label': 'cellphone'}\n",
      "[array([[ 1.7849137, -2.0709918]], dtype=float32)]\n",
      "91.jpg {'xmin': 347, 'xmax': 393, 'ymin': 140, 'ymax': 182, 'label': 'cellphone'}\n",
      "[array([[ 4.048107, -4.076702]], dtype=float32)]\n",
      "92.jpg {'xmin': 328, 'xmax': 373, 'ymin': 161, 'ymax': 201, 'label': 'cellphone'}\n",
      "[array([[ 2.9081163, -3.0668762]], dtype=float32)]\n",
      "93.jpg {'xmin': 328, 'xmax': 373, 'ymin': 157, 'ymax': 196, 'label': 'cellphone'}\n",
      "[array([[ 2.9647875, -3.1222875]], dtype=float32)]\n",
      "94.jpg {'xmin': 334, 'xmax': 377, 'ymin': 159, 'ymax': 195, 'label': 'cellphone'}\n",
      "[array([[ 1.5540998, -1.8710243]], dtype=float32)]\n",
      "95.jpg {'xmin': 337, 'xmax': 381, 'ymin': 154, 'ymax': 190, 'label': 'cellphone'}\n",
      "[array([[ 0.5230202, -0.9592705]], dtype=float32)]\n",
      "97.jpg {'xmin': 140, 'xmax': 178, 'ymin': 257, 'ymax': 292, 'label': 'cellphone'}\n",
      "[array([[ 0.9490122, -1.3336507]], dtype=float32)]\n",
      "98.jpg {'xmin': 345, 'xmax': 389, 'ymin': 141, 'ymax': 180, 'label': 'cellphone'}\n",
      "[array([[ 3.2030923, -3.327089 ]], dtype=float32)]\n",
      "誤差率: 81.25 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for file in dir_list:\n",
    "    img = cv2.imread(path_cellphone+file)\n",
    "    yolo_info = get_yolo_info(img)\n",
    "    if yolo_info != False:\n",
    "        print(file, yolo_info)\n",
    "        #cv2.imwrite(path_original+file, draw(img, yolo_info))\n",
    "        #expansion process\n",
    "        bbox = pre_mlp(img,yolo_info,expansion_rate)\n",
    "        cv2.imwrite(path_premlp+file, bbox)\n",
    "        #preprocess\n",
    "        bbox = cv2.resize(bbox,size_mlp_data)\n",
    "        bbox = cv2.cvtColor(bbox, cv2.COLOR_BGR2GRAY)\n",
    "        bbox = bbox.flatten()\n",
    "        #print(bbox.shape)\n",
    "        #tmpx\n",
    "        tmpx = np.array([]).reshape((0, img2.shape[0]))\n",
    "        tmpx = np.row_stack([tmpx, bbox.flatten()])\n",
    "        tmpx /= 255\n",
    "        #tmpy\n",
    "        tmpy = np.array([]).reshape((0, y_train.shape[1]))\n",
    "        tmpy = np.row_stack([tmpy, class_y[0]])\n",
    "        tr_pred = sess.run([y_pred], feed_dict={input_data:tmpx})\n",
    "        if tr_pred[0][0][0] > tr_pred[0][0][1]:\n",
    "            print(tr_pred)\n",
    "            img = draw(img, yolo_info)\n",
    "            cv2.imwrite(path_result_folder+file, img)\n",
    "            count += 1\n",
    "print(\"誤差率:\", 100*count/len(dir_list),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20180628']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "video_list = [\"20180628\"]\n",
    "print(video_list)\n",
    "print(len(video_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.avi', '1.avi', '10.avi', '11.avi', '12.avi', '13.avi', '14.avi', '15.avi', '16.avi', '17.avi', '18.avi', '19.avi', '2.avi', '20.avi', '21.avi', '22.avi', '23.avi', '24.avi', '3.avi', '4.avi', '5.avi', '6.avi', '7.avi', '8.avi', '9.avi']\n",
      "Now processing: 0.avi 1 / 25\n"
     ]
    }
   ],
   "source": [
    "for d in video_list:\n",
    "    date = d\n",
    "    path_video = \"../FullVideo/\"+date+\"/\"\n",
    "    path_video_premlp = path_video+\"premlp/\"\n",
    "    path_video_result_folder = \"../FullVideo/results/\"+date+\"/\"\n",
    "    path_video_result_folder2 = \"../FullVideo/results/\"+date+\"/\"+\"original/\"\n",
    "    path_video_yolo = path_video+\"yolo/\"\n",
    "\n",
    "#     if not os.path.isdir(path_video_premlp):\n",
    "#         os.makedirs(path_video_premlp)\n",
    "    if not os.path.isdir(path_video_result_folder):\n",
    "        os.makedirs(path_video_result_folder)\n",
    "    if not os.path.isdir(path_video_result_folder2):\n",
    "        os.makedirs(path_video_result_folder2)\n",
    "\n",
    "    video_list = []\n",
    "    for video in os.listdir(path_video):\n",
    "        if 'avi' in video:\n",
    "            video_list.append(video)\n",
    "    print(video_list)\n",
    "\n",
    "    total = 0\n",
    "    count = 0\n",
    "    switch = 1\n",
    "    move_list = []\n",
    "    stop_count = []\n",
    "    move_count = []\n",
    "    status_list = []\n",
    "    stop_rate = 0.8\n",
    "    start_rate = 0.2\n",
    "    standard = 0\n",
    "    vnum = 1\n",
    "    for video in video_list:\n",
    "        print('Now processing:', video, vnum,\"/\",len(video_list))\n",
    "        vnum+=1\n",
    "        cap = cv2.VideoCapture(path_video+video)\n",
    "        timeF = 100\n",
    "        c = 0\n",
    "        # 以迴圈從影片檔案讀取影格，並顯示出來\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if(c%timeF==0):\n",
    "                print(c)\n",
    "                #判斷車子是否行進間   \n",
    "    #             new_img = frame[100:250,350:500]\n",
    "                new_img = frame[100:250,360:500]\n",
    "                if c==0:\n",
    "                    ret,previous = cv2.threshold(new_img,127,255,cv2.THRESH_BINARY)\n",
    "                else:\n",
    "                    ret,current = cv2.threshold(new_img,127,255,cv2.THRESH_BINARY)\n",
    "                    minus = cv2.subtract(current,previous)\n",
    "                    previous = current.copy()\n",
    "                    move = np.sum(minus/255)\n",
    "\n",
    "    #                 cv2.imshow('mytitle',minus)\n",
    "    #                 #print(move)\n",
    "    #                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #                     break\n",
    "    #                 if c== 3000:\n",
    "    #                     cap.release()\n",
    "    #                     cv2.destroyAllWindows()\n",
    "\n",
    "                    if move < 2000:\n",
    "                        status_list.append(0)\n",
    "                    else:\n",
    "                        status_list.append(1)\n",
    "\n",
    "                    if len(status_list) == 10:\n",
    "                        if sum(status_list) < 10*(1-stop_rate):\n",
    "                            switch = 0\n",
    "                        if sum(status_list) > 10*start_rate:\n",
    "                            switch = 1\n",
    "                        #print(status_list, switch)\n",
    "                        status_list.pop(0)\n",
    "\n",
    "\n",
    "\n",
    "                #print(type(frame))\n",
    "                img = frame[:,5:300]\n",
    "\n",
    "\n",
    "                if switch == 1:\n",
    "                    yolo_info = get_yolo_info(img)\n",
    "                    if yolo_info != False:\n",
    "                        #print(yolo_info)\n",
    "                        #yolo = draw(img, yolo_info)\n",
    "                        #cv2.imwrite(path_video_yolo+str(c)+\".jpg\", yolo)\n",
    "                        #cv2.imwrite(path_original+file, draw(img, yolo_info))\n",
    "                        #expansion process\n",
    "                        bbox = pre_mlp(img,yolo_info,expansion_rate)\n",
    "                        #cv2.imwrite(path_video_premlp+video[:video.index('.')]+'_'+str(count)+\".jpg\", bbox)\n",
    "                        #print(path_video_premlp+str(count)+\".jpg\")\n",
    "                        #preprocess\n",
    "                        bbox = cv2.resize(bbox,size_mlp_data)\n",
    "                        bbox = cv2.cvtColor(bbox, cv2.COLOR_BGR2GRAY)\n",
    "                        #print(bbox.shape)\n",
    "                        bbox = bbox.flatten()\n",
    "                        #print(bbox.shape)\n",
    "                        #tmpx\n",
    "                        tmpx = np.array([]).reshape((0, img2.shape[0]))\n",
    "                        tmpx = np.row_stack([tmpx, bbox.flatten()])\n",
    "                        tmpx /= 255\n",
    "                        #tmpy\n",
    "                        tmpy = np.array([]).reshape((0, y_train.shape[1]))\n",
    "                        tmpy = np.row_stack([tmpy, class_y[0]])\n",
    "                        tr_pred = sess.run([y_pred], feed_dict={input_data:tmpx})\n",
    "                        if tr_pred[0][0][0] > tr_pred[0][0][1]:\n",
    "                        #if tr_pred[0][0][0] > 0.5:\n",
    "                            print(tr_pred)\n",
    "                            img = draw(img, yolo_info)\n",
    "                            cv2.imwrite(path_video_result_folder+video[:video.index('.')]+'_'+str(count)+\".jpg\", img)\n",
    "                            cv2.imwrite(path_video_result_folder2+video[:video.index('.')]+'_'+str(count)+\".jpg\", frame)\n",
    "                            print(path_video_result_folder+video[:video.index('.')]+'_'+str(count)+\".jpg\")\n",
    "                        count += 1\n",
    "            c += 1\n",
    "        print('total count:', count)\n",
    "        print('----------------------------')\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        #print('Object detected files:',count,'/',total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
